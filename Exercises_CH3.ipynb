{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3.1\n",
    "1. a short-term stock-trading agent\n",
    "  * targets a single stock\n",
    "  * initially owns $M_0$ amount of currency and $S_0$ units of stock\n",
    "  * can purchase up to $M_max$ at every time step $t \\in \\{1, 2, ...\\}$, at a stock price of $P_t$\n",
    "  * **goal**: maximize obtained currency after $T_{max}$ steps\n",
    "  * **state**: number of stocks owned $M_t$, amount of currency owned $S_t$, current stock price $P_t$\n",
    "  * **actions**: do nothing; or purchase 1/2/.../$\\lfloor \\frac{min(M_t, M_{max})}{P_t} \\rfloor$ unit of stocks based on current stock price; or sell 1/2/.../$S_t$ units of stocks at current stock price\n",
    "  * **reward**: amount of currency at final time step, $M_{T_{max}}$\n",
    "  \n",
    "2. a vacuum-cleaning robot\n",
    "  * operates in a bounded environment, represented as a 2-D grid of cells $(i,j)$\n",
    "  * state of each cell $W[i, j]$: DIRTY, CLEAN, OBJECT; initially all cells are either occupied by OBJECT or DIRTY\n",
    "  * pose of robot at timestep $t$: $P_t$; initially $(0, 0)$\n",
    "  * **goal**: clean all free cells as quickly as possible\n",
    "  * **state**: robot pose $P_t$, state of environment $W_t$\n",
    "  * **actions**: IDLE; or MOVE LEFT/RIGHT/UP/BOTTOM\n",
    "  * if robot attempts to move outside the environment, then the action has no effect on the state\n",
    "  * state is terminal if no cells are DIRTY; all subsequent actions are identical to IDLE and have no effect on the state\n",
    "  * **reward**: at $T_max$ steps, +1 if goal attained\n",
    "\n",
    "3. block-stacking arm robot\n",
    "  * arm has several actuated joint, and a gripper that can OPEN or CLOSE\n",
    "  * environment has a BLUE and a RED square block, both on the ground\n",
    "  * **goal**: place BLUE on RED, with arm \n",
    "  * **state**: state of each arm joint, state of gripper; x/y/z positions of BLUE block, RED block, and gripper\n",
    "  * **actions**: open/close gripper, or move one of the joint by +/- amount (within bounds)\n",
    "  * **reward**: +1 if BLUE is on RED **and** position of gripper is not within $M$ distance from either blocks  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3.2\n",
    "* If the state is only partially observable, then we can either treat it as a generic non-stationary MDP with partial state, or apply the more generalized theory of Partially-Observable MDP (POMDP)\n",
    "* In game-playing situations where the opponent agent(s) may adjust their strategies based on our agent's actions, then we can either treat it as a generic non-stationary MDP, or apply game-theoretic extensions of MDP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3.3\n",
    "* All levels of action/control abstraction are *feasible/valid*\n",
    "* When we opt for an action space with high level of abstraction, we are implicitly assuming the existence of controller or transformation function that implements the high-level actions as low-level control signals\n",
    "* For instance, when we control the steering wheel, we are implicitly relying on a power-steering system, or at the minimum, a system of gears, axles, and shafts, in conjunction to the engine, in order to translate to wheel torques\n",
    "* Abstract action spaces are preferred because they have smaller cardinality, and/or more more intuitive to manual control\n",
    "* Nevertheless, the goal-efficacy of these actions depend on the correctness, latency, and efficacy of the above-mentioned high-to-low-abstraction controllers and/or transformation functions\n",
    "* Consequently, RL agents using abtract action spaces tend to learn faster, while agents using low-level action spaces tend to learn high-reward policies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3.4\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
